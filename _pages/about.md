---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- ## About Me -->
I am a second-year PhD student at [The Hong Kong University of Science and Technology](https://hkust.edu.hk), [Department of Computer Science and Engineering](https://cse.hkust.edu.hk/).
I am fortunate to be advised by [Junxian He](https://jxhe.github.io/). 
I am generally interested in large language models and vision language models, with experiences in model merging, long context modeling and multiturn reasoning.

## üìù Publications
Most recent publications on [Google Scholar](https://scholar.google.com/citations?user=HqF5d38AAAAJ&hl=en).  
\* denotes co-first authors, $^\dagger$ denotes corresponding author/main advisor

<!--vlmmerging-->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='_pages/images/vlmmerging.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging**

Shiqi Chen\*, *<ins>Jinghan Zhang</ins>*\*, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, Junxian He$^\dagger$  

<p><a href="https://arxiv.org/abs/2505.05464">paper</a> | <a href="https://github.com/shiqichen17/VLM_Merging"><img src="https://img.shields.io/github/stars/shiqichen17/VLM_Merging?style=social" alt="" /></a></p>

- **Abstract**: We enhance VLM reasoning via model merging and understand perception and reasoning ability inside model.
</div>
</div>

<!--adaptvis-->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='_pages/images/adaptvis.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Why Is Spatial Reasoning Hard for VLMs? An Attention Mechanism Perspective on Focus Areas**

Shiqi Chen, Tongyao Zhu, Ruochen Zhou, *<ins>Jinghan Zhang</ins>*, Siyang Gao, Juan Carlos Niebles, Mor Geva, Junxian He, Jiajun Wu, Manling Li$^\dagger$  

<p><a href="https://arxiv.org/abs/2503.01773">paper</a> | <a href="https://huggingface.co/datasets/AdaptVis/all_datasets">dataset</a> | <a href="https://github.com/shiqichen17/AdaptVis"><img src="https://img.shields.io/github/stars/shiqichen17/AdaptVis?style=social" alt="" /></a></p>

- **Abstract**: A training-free decoding method called AdaptVis boosts VLM‚Äôs spatial reasoning by dynamically sharpening or broadening attention based on confidence, yielding up to 50-point accuracy gains on benchmarks.
</div>
</div>

<!--compression-->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">COLM 2024</div><img src='_pages/images/compression.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Compression Represents Intelligence Linearly**

Yuzhen Huang\*, *<ins>Jinghan Zhang</ins>*\*, Zifei Shan, Junxian He$^\dagger$  

<p><a href="https://arxiv.org/abs/2404.09937">paper</a> | <a href="https://huggingface.co/spaces/hkust-nlp/LLM_Compression_Leaderboard">leaderboard</a> | <a href="https://huggingface.co/datasets/hkust-nlp/llm-compression">dataset</a> | <a href="https://github.com/hkust-nlp/llm-compression-intelligence"><img src="https://img.shields.io/github/stars/hkust-nlp/llm-compression-intelligence?style=social" alt="" /></a></p>

- **Abstract**: In this paper, we study the relationship between compression rate and intelligence of LLMs.
</div>
</div>

<!--pem merging-->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='_pages/images/neurips2023merge_finalv-1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Composing Parameter-Efficient Modules with Arithmetic Operations**

*<ins>Jinghan Zhang</ins>*, Shiqi Chen, Junteng Liu, Junxian He$^\dagger$  

<p><a href="https://arxiv.org/abs/2306.14870">paper</a> | <a href="https://github.com/hkust-nlp/PEM_composition"><img src="https://img.shields.io/github/stars/hkust-nlp/PEM_composition?style=social" alt="" /></a></p>

- **Abstract**: In this paper, we study model merging on parameter-efficient modules like LoRA and (IA)^3.
</div>
</div>

<!--ceval-->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023 D&B</div><img src='_pages/images/ceval.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models**  

Yuzhen Huang\*, Yuzhuo Bai\*, Zhihao Zhu, Junlei Zhang, *<ins>Jinghan Zhang</ins>*, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, Junxian He$^\dagger$  

<p><a href="https://arxiv.org/abs/2305.08322">paper</a> | <a href="https://cevalbenchmark.com">website</a> | <a href="https://huggingface.co/datasets/ceval/ceval-exam">dataset</a> | <a href="https://github.com/hkust-nlp/ceval"><img src="https://img.shields.io/github/stars/hkust-nlp/ceval?style=social" alt="" /></a></p>

</div>
</div>

<!--felm-->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023 D&B</div><img src='_pages/images/felm_examples.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**FELM: Benchmarking Factuality Evaluation of Large Language Models**  

Shiqi Chen, Yiran Zhao, *<ins>Jinghan Zhang</ins>*, I-Chun Chern, Siyang Gao, Pengfei Liu, Junxian He$^\dagger$  

<p><a href="https://arxiv.org/abs/2310.00741">paper</a> | <a href="https://hkust-nlp.github.io/felm/">website</a> | <a href="https://huggingface.co/datasets/hkust-nlp/felm">dataset</a> | <a href="https://github.com/hkust-nlp/felm"><img src="https://img.shields.io/github/stars/hkust-nlp/felm?style=social" alt="" /></a></p>

</div>
</div>

<!-- **Composing Parameter-Efficient Modules with Arithmetic Operations**  
*<ins>Jinghan Zhang</ins>*, Shiqi Chen, Junteng Liu, Junxian He$^\dagger$  
NeurIPS 2023. [[arxiv]](https://arxiv.org/abs/2306.14870) [[github]](https://github.com/hkust-nlp/PEM_composition)

**C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models**  
Yuzhen Huang\*, Yuzhuo Bai\*, Zhihao Zhu, Junlei Zhang, *<ins>Jinghan Zhang</ins>*, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, Junxian He$^\dagger$  
NeurIPS 2023 (Datasets and Benchmarks track). [[arxiv]](https://arxiv.org/abs/2305.08322) [[github]](https://github.com/hkust-nlp/ceval) [[website]](https://cevalbenchmark.com) [[dataset]](https://huggingface.co/datasets/ceval/ceval-exam)

**FELM: Benchmarking Factuality Evaluation of Large Language Models**  
Shiqi Chen, Yiran Zhao, *<ins>Jinghan Zhang</ins>*, I-Chun Chern, Siyang Gao, Pengfei Liu, Junxian He$^\dagger$  
NeurIPS 2023 (Datasets and Benchmarks track). [[arxiv]](https://arxiv.org/abs/2310.00741) [[github]](https://github.com/hkust-nlp/felm) [[website]](https://hkust-nlp.github.io/felm/) [[dataset]](https://huggingface.co/datasets/hkust-nlp/felm)
-->

## üåü Service
Reviewer: NeurIPS, ICLR, ICML, COLM, ACL Demo, NLPCC

## üéñ Awards
- *2024.9* COLM 2024 DEI Scholarship
- *2023.10* NeurIPS 2023 Scholar Award
- *2023.06* Outstanding Undergraduate Thesis in SEU (top 3%)  
- *2021.12* National Scholarship 

## üìñ Education
- *2024.02 - now* PhD student, Department of CSE, [HKUST](https://hkust.edu.hk), Hong Kong SAR, China.
- *2023.11 - 2024.01* Research Assistant, Department of CSE, [HKUST](https://hkust.edu.hk), Hong Kong SAR, China.
- *2019.09 - 2023.06* Undergraduate, Artificial Intelligence, [Southeast University](https://www.seu.edu.cn/), Nanjing, China.

<!--## üßëüèª‚Äçüíª Contact
Happy to chat about any topics :)
-->

<!-- Calendly badge widget begin -->
<link href="https://assets.calendly.com/assets/external/widget.css" rel="stylesheet">
<script src="https://assets.calendly.com/assets/external/widget.js" type="text/javascript" async></script>
<script type="text/javascript">window.onload = function() { Calendly.initBadgeWidget({ url: 'https://calendly.com/zhangcharlotte84/15min', text: 'Happy to chat about any topics :)', color: '#2162da', textColor: '#ffffff', branding: undefined }); }</script>
<!-- Calendly badge widget end -->
